---
title: "Second Amendment Dependencies: Pilot Analysis"
author: "DGK"
date: "Q1 2025"
output:
  html_document: default
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library Setup

```{r}
library(tidyverse)  # for data manipulation
library(lme4)       # for glmer and lmer models
library(ordinal)    # for clmm ordinal logistic regression
```

# Initial Formatting

## Set up file paths

```{r}
numeric_file <- "/Users/dgkamper/My Drive (dgkamper@gmail.com)/DGK Lab/Collaborations/BlankLang Lab/DGK Lab - BlankLangLab - Second Amendment Language Dependencies/Analysis/Cleaned_Numeric_Second Amendment Dependencies_Pilot.csv"
response_file <- "/Users/dgkamper/My Drive (dgkamper@gmail.com)/DGK Lab/Collaborations/BlankLang Lab/DGK Lab - BlankLangLab - Second Amendment Language Dependencies/Analysis/Cleaned_Response_Second Amendment Dependencies_Pilot.csv"  # extra file for reponse checking
```

## Read the numeric file

```{r}
df_numeric <- read_csv(numeric_file)
df_response <- read_csv(response_file)
```


```{r}
# Pivot the sentence-specific columns to long format.
# The column names have the form: [QuestionType][SentenceNumber]
# For example: Rewrite2, Interpretation2, Confidence2, IsTrue2, Remove2.
# We use the pivot_longer() function with a regex pattern that splits the name into two parts:
#   - .value: the question type (e.g., Rewrite, Interpretation, etc.)
#   - sentence: the sentence number.
df_long <- df_numeric %>%
  pivot_longer(
    cols = matches("^(Rewrite|Interpretation|Confidence|IsTrue|Remove)[0-9]+$"),
    names_to = c(".value", "sentence"),
    names_pattern = "([A-Za-z]+)([0-9]+)"
  ) %>%
  # Since each participant was assigned only one sentence, we filter out rows where the key response is missing.
  filter(!is.na(Rewrite)) %>%
  # Convert sentence identifier to numeric
  mutate(sentence = as.integer(sentence))

# Inspect the first few rows of the reshaped data
head(df_long)

# Save the df_long as CSV file
write.csv(df_long, "df_long.csv")
```

# Analysis Models

## Participant Exclusion Based on Attention Checks

```{r}
df_long <- df_long %>%
  mutate(
    # AttentionCheck1 == 3 means correct
    screen_pass = (AttentionCheck1 == 3),
    
    # Police1 == 2 means correct
    comp1 = if_else(Police1 == 2, 0, 1),
    
    # Police2 == 2 means correct
    comp2 = if_else(Police2 == 2, 0, 1),
    
    # Police3 == 1 means correct
    comp3 = if_else(Police3 == 1, 0, 1),
    
    comp_total = comp1 + comp2 + comp3
  ) %>%
  filter(screen_pass == TRUE, comp_total < 2, Seriousness == 4)
```

## Create Analysis Variables

```{r}
df_long <- df_long %>%
  mutate(
    # Recode Interpretation from {1,2} to {0,1} for logistic regression
    Q2_Interpretation_bin = case_when(
      Interpretation == 1 ~ 0,
      Interpretation == 2 ~ 1,
      TRUE ~ NA_real_
    ),
    
    # Make Q4 (IsTrue) an ordered factor for ordinal logistic regression
    Q4_IsTrue_ord = factor(IsTrue, ordered = TRUE),
    
    # Center Q5 (Remove) by subtracting 4, so midpoint (4) becomes 0
    Q5_Remove_centered = Remove - 4
  )
```

## Question 2: Interpreting “Being Necessary”

Here we assume that the variable Response is a binary indicator (1 = “only in cases when it’s necessary”, 2 = “always necessary”). A logistic mixed-effects model with a random intercept for sentence is used.

```{r}
model_q2 <- glmer(
  Q2_Interpretation_bin ~ 1 + (1 | sentence),
  data = df_long,
  family = binomial
)

summary(model_q2)
```

## Question 3: Confidence Ratings

This model tests whether confidence ratings differ based on the interpretation (i.e. Interpretation). A linear mixed-effects model is fitted with random slopes and intercepts for sentence.

```{r}
model_q3 <- lmer(
  Confidence ~ 1 + Q2_Interpretation_bin + (1 + Q2_Interpretation_bin | sentence),
  data = df_long
)

summary(model_q3)
```

## Question 4: Ordinal Logistic Regression for Perceived Impact
Assuming Question 3 responses captures the ordered response (e.g., how much the introductory clause impacts meaning), we first convert it into an ordered factor. Then we fit an ordinal logistic regression model with a random intercept for sentence.

```{r}
model_q4 <- clmm(
  Q4_IsTrue_ord ~ 1 + (1 | sentence),
  data = df_long,
  link = "logit"
)

summary(model_q4)
```

Does Q2 predict Q4? Add Q2 as a fixed effect.

```{r}
model_q4_alt <- clmm(
  Q4_IsTrue_ord ~ Q2_Interpretation_bin + (1 | sentence),
  data = df_long,
  link = "logit"
)
summary(model_q4_alt)
```

Just for checking purposes, let us consider that there might be random slopes for Q2 on confidence in general (this might be wrong, but worth a shot given power)

```{r}
model_q4_alt_slopes <- clmm(
  Q4_IsTrue_ord ~ Q2_Interpretation_bin + (1 + Q2_Interpretation_bin | sentence),
  data = df_long,
  link = "logit"
)
summary(model_q4_alt_slopes)
```

Looking at these results, both models produced singular fits, so we could not  reliably estimate standard errors (resulting in warnings and NaN values). Therefore, let us try ordinal logistic regression without random effects (using clm). And we also ordinal logistic regression where we include sentence (as a factor) to account for systematic differences across stimuli (with clm)

```{r}
model_q4_clm <- clm(
  Q4_IsTrue_ord ~ Q2_Interpretation_bin,
  data = df_long,
  link = "logit"
)
summary(model_q4_clm)
```


```{r}
model_q4_clm_fixed <- clm(
  Q4_IsTrue_ord ~ Q2_Interpretation_bin + factor(sentence),
  data = df_long,
  link = "logit"
)
summary(model_q4_clm_fixed)
```

## Question 5: Impact of Clause Removal

For this model, we center the response by subtracting 4 (so that a neutral midpoint equals 0) and then fit a linear mixed-effects model with a random intercept for sentence.

```{r}
model_q5 <- lmer(
  Q5_Remove_centered ~ 1 + (1 | sentence),
  data = df_long
)

summary(model_q5)
```

If we believe that the effect of interpretation (Q2) might also affect Q5 differently across sentences, we can add it as a fixed effect with random slopes.

```{r}
model_q5_alt <- lmer(
  Q5_Remove_centered ~ 1 + Q2_Interpretation_bin + (1 + Q2_Interpretation_bin | sentence),
  data = df_long
)

summary(model_q5_alt)
```

# Analysis Interpretations

## Question 2: Interpreting “Being Necessary”

Fixed effect (Intercept): 1.59 (SE = 0.24), z = 6.64, p < .001

On the log-odds scale, an intercept of 1.59 corresponds to a probability of roughly 0.83. Thus, about 83% of participants chose the “always necessary” interpretation overall, significantly above chance (50%).

The random effect variance for sentence was effectively zero, suggesting minimal variability across the 20 different sentences in how often participants picked “always necessary.”

Interpretation: Participants strongly favored reading the “being necessary” clause as an unconditional statement, rather than interpreting it as applying “only in certain cases.”

## Question 3: Confidence Ratings

Fixed Intercept: 4.89 (SE = 0.39), t = 12.59
Effect of Q2_Interpretation_bin: 0.37 (SE = 0.44), t = 0.84, p = .40

Although participants who selected “always necessary” reported slightly higher mean confidence (about 5.26 vs. 4.89), this difference was not statistically reliable (p = .40). The random effects structure indicated some variability across sentences, but overall the slope for interpretation did not significantly differ by sentence.

Interpretation: Regardless of whether they interpreted the clause as “always necessary” or “only in certain cases,” participants showed similar confidence in their chosen interpretation.

## Question 4: Ordinal Logistic Regression for Perceived Impact

Although the initial approach used a cumulative link mixed model (clmm) with a random intercept for sentence, that model yielded singular fits (i.e., near-zero estimated variance for the sentence random effect and unstable standard errors). This suggested that between-sentence variability in Q4 responses was negligible.

Consequently, using a simplified analysis by employing a cumulative link model (clm) without random effects, I also explored a model including sentence as a fixed effect to account for any systematic differences among stimuli.

The clm yielded a coefficient for Q2 of 0.08974 (SE = 0.44546, z = 0.201, p = 0.84) along with threshold estimates of –0.3187 (SE = 0.4075) and 0.1381 (SE = 0.4067).

Interpretation: These results indicate that participants’ binary interpretation of “being necessary” (always vs. only in certain cases) did not significantly predict how strongly they viewed the main clause as contingent upon the introductory clause. When including sentence as a fixed factor, the coefficient for Q2 was 0.1888 (SE = 0.5013, z = 0.377, p = 0.706). Controlling for sentence-level differences did not alter this non-significant relationship.

## Question 5: Impact of Clause Removal

Fixed Intercept: –0.21 (SE = 0.15), t = –1.38, p = .17

Random intercept variance was effectively zero.

The negative intercept suggests the mean rating was slightly below the midpoint (i.e., ~3.79 on the original scale of 1–7), but not significantly different from 4. Adding Q2 interpretation as a predictor did not significantly alter Q5 scores or improve model fit (–0.55, p = .20).

Interpretation: On average, participants did not strongly indicate that removing the introductory clause drastically changed the meaning. The mean hovered near the neutral midpoint, and no systematic difference emerged between those who read the sentence as “always necessary” vs. “only in cases.”

## General Analysis Discussion

The present analyses examined how participants interpret a syntactically complex “being necessary” clause, their confidence in that interpretation, their judgments regarding the dependency of the main clause on the introductory clause, and the perceived impact of removing the introductory clause. The results can be summarized as follows:

Interpretation of “Being Necessary” (Q2):
The logistic mixed-effects model for Q2 revealed a strong tendency for participants to adopt an unconditional interpretation—approximately 83% chose the “always necessary” option. This robust finding suggests that, when faced with these syntactic constructions, participants overwhelmingly read the introductory clause as establishing an absolute condition rather than a context-dependent qualifier. The lack of meaningful between-sentence variability (as indicated by the near-zero random-effect variance) implies that this pattern holds consistently across different sentence stimuli.

Confidence in Interpretation (Q3):
The analysis of confidence ratings showed that participants reported high confidence overall (mean around 4.89 on a 7-point scale). Although there was a slight, non-significant increase in confidence for those who interpreted the clause as “always necessary,” the effect did not reach significance. This suggests that irrespective of the chosen interpretation, participants felt similarly certain about their reading of the sentence, perhaps indicating that the decision is made quickly and with little ambiguity for most readers.

Perceived Impact of the Introductory Clause (Q4):
Our initial attempt to account for variability across sentences using a cumulative link mixed model (clmm) encountered technical difficulties, as the estimated random effects were near zero. A simplified approach using a cumulative link model (clm) was therefore adopted. Whether or not sentence-level differences were explicitly modeled (by including sentence as a fixed effect), the relationship between participants’ interpretation of “being necessary” and their judgments about the contingency of the main clause was non-significant. This finding implies that the decision regarding the unconditional versus conditional nature of the introductory clause does not meaningfully alter the extent to which participants view the main clause as dependent on it.

Impact of Clause Removal (Q5):
The analysis of Q5, which measured the perceived change in meaning when the introductory clause is removed, produced a mean rating that was only slightly below the neutral midpoint. Furthermore, the inclusion of interpretation (Q2) as a predictor did not significantly explain additional variance in Q5 responses. This result indicates that, on average, the removal of the introductory clause does not lead to a dramatic shift in perceived meaning. In other words, participants appear to view the main clause as relatively stable, regardless of whether the prefatory “being necessary” clause is present.

Overall Interpretation and Theoretical Implications:
Collectively, these findings suggest that while participants overwhelmingly adopt an unconditional reading of "being necessary," this interpretation does not significantly influence their confidence, perceptions of dependency, or judgments about the impact of clause removal. For reference, here is the Second Amendment:

"A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed."

Our results indicate that, when faced with similarly structured sentences, lay readers tend to interpret the "being necessary" clause as an absolute statement rather than a conditional qualifier. Specifically, readers appear to process such clauses as independent factual assertions rather than as premises in a logical relationship with the operative clause. 

Consider this logic:

Conditional Reading: "IF (militia is necessary for security) THEN (right shall not be infringed)"

Purpose Reading: "(right shall not be infringed) FOR THE PURPOSE OF (having necessary militia)"

Absolute Reading: "FACT: (militia is necessary for security)" AND "FACT: (right shall not be infringed)"

Put more simply, suppose we have the two concepts here:

"Since it's raining outside, you need to take an umbrella."

Here, the action (taking an umbrella) is directly tied to the condition (it's raining). You only need the umbrella because it's raining.

"It's raining outside. By the way, you need to take an umbrella."

Here, the rain is just background information. You should take the umbrella regardless of the rain.

But our research shows that most people read it more like:

"It's raining outside. You need to take an umbrella."

They see these as two separate facts: (1) it is raining and (2) you need an umbrella. They don't try to figure out if one fact depends on the other - they just accept both statements as independently true.

Applied to the Second Amendment, this means most readers see:

Fact 1: "A well regulated Militia is necessary for a free State" (they accept this as true)
Fact 2: "The right to bear arms shall not be infringed" (they also accept this as true)

They don't try to connect these facts in a logical "if-then" relationship. They simply process them as two separate true statements, much like reading "The sky is blue. Water is wet." - two independent facts that don't necessarily have anything to do with each other.

In more formal terms, this suggests that lay readers interpret the text as making two separate categorical assertions: first, that a militia is necessary for security, and second, that the right shall not be infringed. These assertions are processed as parallel truths rather than as logically interdependent propositions. This pattern of interpretation suggests that debates regarding whether the prefatory clause limits the operative right may be less influential in shaping lay interpretations than previously thought. In other words, even if legal scholars and jurists debate whether the clause "being necessary to the security of a free State" restricts the right to bear arms, our pilot data imply that lay readers might uniformly interpret it as affirming a broad, unconditional right, treating the prefatory clause as background context rather than as a limiting condition.

It is important to acknowledge that these findings are based on pilot data with a relatively small sample size and a limited number of stimuli. In particular, the ordinal measure for Q4, with only three response options, may have constrained the ability to detect subtle differences in perceived dependency. Future research should consider employing a more fine-grained measurement scale for Q4 and expanding the sample size to ensure greater statistical power. Additionally, while the current design successfully captures the immediate interpretation of syntactic dependencies, subsequent studies might explore the role of individual differences (e.g., education, political affiliation) in shaping these interpretations.

In summary, our comprehensive analysis indicates that although participants overwhelmingly read the "being necessary" clause as unconditional, this does not translate into significant differences in their confidence, perceived dependency, or assessments of meaning change when the clause is removed. These findings provide preliminary evidence that lay interpretations of complex legal language—such as that found in the Second Amendment—may be more uniform than some theoretical debates suggest, with readers processing prefatory clauses as standalone factual assertions rather than as logical conditions. This has important implications for understanding how constitutional texts are interpreted by the general public and for guiding future research into the effects of syntactic structure on legal interpretation.